---
title: 大数据（十）
date: 2020-01-15 19:23:32
tags: [大数据,impala]
copyright: true
password:
toc: true
---

Impala 是cloudera提供的一款高效率的sql查询工具，提供实时的查询效果，官方测试性能比hive快10到100倍，其sql查询比sparkSQL还要更加快速，号称是当前大数据领域最快的查询sql工具，impala是参照谷歌的新三篇论文（Caffeine、Pregel、Dremel）当中的Dremel实现而来，其中旧三篇论文分别是（BigTable，GFS，MapReduce）分别对应HBase和HDFS以及MapReduce。


本文章主要介绍 Impala 和 在centos环境下如何安装 。

<!--more-->

## Quick Guide


### impala与hive的关系


Impala 是基于 hive 的大数据分析查询引擎，直接使用hive的元数据库metadata，意味着impala元数据都存储在hive的metastore当中，并且impala兼容hive的绝大多数sql语法。所以需要安装impala的话，必须先安装hive，保证hive安装成功，并且还需要启动hive的metastore服务。

### impala的优点

- 1.impala比较快，非常快，特别快，因为所有的计算都可以放入内存当中进行完成，只要你内存足够大
- 2.摈弃了MR的计算，改用C++来实现，有针对性的硬件优化
- 3.具有数据仓库的特性，对hive的原有数据做数据分析
- 4.支持ODBC，jdbc远程访问

### impala的缺点

- 1.基于内存计算，对内存依赖性较大
- 2.改用C++编写，意味着维护难度增大
- 3.基于hive，与hive共存亡，紧耦合
- 4.稳定性不如hive，不存在数据丢失的情况

### impala的架构

![](大数据10_001.png)

- Impala的架构模块：
    - impala-server ==>启动的守护进程，执行我们的查询计划 从节点，官方建议与所有的datanode装在一起，可以通过hadoop的短路读取特性实现数据的快速查询
    - impala-statestore ==》 状态存储区 主节点
    - impalas-catalog ==》元数据管理区 主节点

- frontend生成查询计划分为两个阶段：
    - 1.生成单机查询计划，单机执行计划与关系数据库执行计划相同，所用查询优化方法也类似。
    - 2.生成分布式查询计划。 根据单机执行计划， 生成真正可执行的分布式执行计划，降低数据移动， 尽量把数据和计算放在一起。

- 例如：SQL查询， 该SQL的目标是在三表join的基础上算聚集， 并按照聚集列排序取topN。


![](大数据10_002.png)


### impala的安装

- 0.安装规划

| 服务名称           | master | node01 | node02 | node03 |
| ------------------ | ------ | ------ | ------ | ------ |
| impala-catalog     | 安装   | 不安装 | 不安装 | 不安装 |
| impala-state-store | 安装   | 不安装 | 不安装 | 不安装 |
| impala-server      | 安装   | 安装   | 安装   | 安装   |

- 1.前置
    - 已经安装hadoop
    - 已经安装hive


- 2.可以在[页面](http://archive.cloudera.com/cdh5/redhat/7/x86_64/cdh/5.8.3/RPMS/x86_64/)下载以下RPM包。由于包太多，推荐使用在线yum安装。
- 3.master执行以下命令进行安装 

```bash
yum install impala -y
yum install impala-server -y
yum install impala-state-store  -y
yum install impala-catalog  -y
yum install impala-shell -y
```

- 4.其他节点安装以下服务

```bash
yum install impala-server -y
```

- 5.所有节点配置hive-site.xml

```bash
vim /hadoop/install/apache-hive-3.1.2/conf/hive-site.xml
```

修改内容为：

```xml
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
<configuration>
        <property>
                <name>javax.jdo.option.ConnectionURL</name>
                <value>jdbc:mysql://master:3306/hive?createDatabaseIfNotExist=true</value>
        </property>
        <property>
            <name>javax.jdo.option.ConnectionDriverName</name>
                <value>com.mysql.jdbc.Driver</value>
        </property>
        <property>
                <name>javax.jdo.option.ConnectionUserName</name>
                <value>root</value>
        </property>
        <property>
             <name>javax.jdo.option.ConnectionPassword</name>
                <value>123456</value>
        </property>
        <property>
                <name>hive.cli.print.current.db</name>
                <value>true</value>
        </property>
        <property>
                <name>hive.cli.print.header</name>
                <value>true</value>
        </property>
        <property>
                <name>hive.server2.thrift.bind.host</name>
                <value>master</value>
        </property>
        <property>
                <name>hive.metastore.uris</name>
                <value>thrift://master:9083</value>
        </property>
     <property>
                <name>hive.metastore.client.socket.timeout</name>
                <value>3600</value>
        </property>

</configuration>
```



- 5.master机器启动hive的metastore服务

```
cd /hadoop/install/apache-hive-3.1.2
nohup bin/hive --service metastore &
nohup bin/hive -- service hiveserver2 &
```

- 6.在master机器使用jps查看，有两个 RunJar 表示启动成功

- 7.所有hadoop节点修改hdfs-site.xml添加以下内容
	- 1.所有节点创建文件夹，并给予权限
		
	```bash
	mkdir -p /var/run/hdfs-sockets
	chown  -R  hadoop:hadoop   /var/run/hdfs-sockets/
	```
	
	- 2.修改所有节点的hdfs-site.xml添加以下配置，修改完之后重启hdfs集群生效
    ```
    vim  /hadoop/install/hadoop/etc/hadoop/hdfs-site.xml
    ```

    添加到文件末尾：

    ```xml
    <property>
        <name>dfs.client.read.shortcircuit</name>
        <value>true</value>
    </property>
    <property>
        <name>dfs.domain.socket.path</name>
        <value>/var/run/hdfs-sockets/dn</value>     <!--/var/run/hdfs-socket为目录，dn为文件-->
    </property>
    <property>
        <name>dfs.client.file-block-storage-locations.timeout.millis</name>
        <value>10000</value>
    </property>
    <property>
        <name>dfs.datanode.hdfs-blocks-metadata.enabled</name>
        <value>true</value>
    </property>
    ```

- 8.重启hdfs

```bash
cd /hadoop/install/hadoop/
sbin/stop-dfs.sh
sbin/start-dfs.sh
```

- 9.创建hadoop与hive的配置文件的连接

```bash
# 所有节点 执行以下命令创建链接到impala配置目录下来
ln -s /hadoop/install/hadoop/etc/hadoop/core-site.xml /etc/impala/conf/core-site.xml
ln -s /hadoop/install/hadoop/etc/hadoop/hdfs-site.xml /etc/impala/conf/hdfs-site.xml
ln -s /hadoop/install/apache-hive-3.1.2/conf/hive-site.xml /etc/impala/conf/hive-site.xml
```

- 10.修改impala的配置文件

```bash
# 所有节点更改impala默认配置文件以及添加mysql的连接驱动包
vim /etc/default/impala
IMPALA_CATALOG_SERVICE_HOST=master
IMPALA_STATE_STORE_HOST=master

# 所有节点创建mysql的驱动包的软连接
ln -s /hadoop/install/apache-hive-3.1.2/lib/mysql-connector-java-5.1.38.jar
/usr/share/java/mysql-connector-java.jar

# 所有节点修改bigtop的java_home路径
vim /etc/default/bigtop-utils
export JAVA_HOME=/hadoop/install/jdk1.8.0_141
```

- 11.master节点启动impala服务

```bash
service impala-state-store start
service impala-catalog start
service impala-server start
```

- 12.其他节点启动impala-server

```bash
service  impala-server  start
```

- 13.查看impala进程是否存在

```bash
ps -ef | grep impala
```

- 14.浏览器页面访问

```
访问impalad的管理界面: http://master:25000/
访问statestored的管理界面: http://master:25010/
访问catalog的管理界面: http://master:25020
```

**注意：启动之后所有关于impala的日志默认都在/var/log/impala 这个路径下**

More info: [Impala](https://www.cnblogs.com/-xiaoyu-/p/11186670.html)

