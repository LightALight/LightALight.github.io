---
title: 大数据（六）Hadoop的部署
date: 2019-09-15 19:23:32
tags: [大数据,hadoop]
copyright: true
password:
toc: true
---

本文章主要介绍在centos环境下如何安装Hadoop。

<!--more-->
## Quick Guide

### 下载并安装Hadoop

* 1.使用以下命令添加Hadoop系统用户
```bash
sudo addgroup hadoop # 新建用户组   
sudo adduser --ingroup hadoop hadoop # 新建用户
```
**注意：**出现这个报错"hadoop is not in the sudoers file. This incident will be reported.",可以通过以root用户身份登录解决此错误

* 2.配置SSH
```bash
su - hadoop # 切换用户
ssh-keygen -t rsa -P "" # 创建一个新密钥
cat $HOME/.ssh/id_rsa.pub >> $HOME/.ssh/authorized_keys # 启用密钥
ssh localhost # 测试是否可用
```

**注意：**出现 openssh-server没安装的错误，请使用下面命令安装
```bash
yum openssh-server
```

* 3.下载Hadoop

    * 3.1 点击[Hadoop](http://apache.org/dyn/closer.cgi/hadoop/core)链接,再点击镜像地址
    ![](/image/大数据06/大数据06_001.png)
    
	* 3.2 选择稳定版本
    ![](/image/大数据06/大数据06_002.png)
    
	* 3.3 选择tar.gz文件（文件名没有'src'）
    ![](/image/大数据06/大数据06_003.png)

* 4.放到服务器解压
```bash
sudo tar xzf hadoop-3.2.1.tar.gz -C /hadoop/install # 解压
cd /hadoop/install
sudo mv hadoop-3.2.1 hadoop # 修改文件名
sudo chown -R hadoop:hadoop hadoop # 目录增加用户权限
```

### 配置Hadoop

#### 配置环境变量

```bash
export HADOOP_HOME=<Hadoop的安装路径> # 设置HADOOP_HOME
export JAVA_HOME=<Java的安装路径> # 设置JAVA_HOME
export PATH=$PATH:$HADOOP_HOME/bin # 将Hadoop的bin目录添加到PATH
. ~/.bashrc # 环境下应用该配置
```

#### 配置 **HDFS**

##### 配置环境变量
在 **$HADOOP_HOME/etc/hadoop/hadoop-env.sh** 设置 **JAVA_HOME**

配置前：
![](/image/大数据06/大数据06_004.png)

配置后：	   
![](/image/大数据06/大数据06_005.png)

##### 配置核心组件文件

**$HADOOP_HOME/etc/hadoop/core-site.xml** 中有两个参数
* **hadoop.tmp.dir -**  用于Hadoop的存储数据文件的目录 
* **fs.default.name -** 指定默认的文件系统 

* 1.打开文件
```bash
sudo gedit $HADOOP_HOME/etc/hadoop/core-site.xml
```
* 2.复制下面配置到 文件内容的 `<configuration>` 和 `</configuration>` 之间
```xml
<property>
<name>hadoop.tmp.dir</name>
<value>/hadoop/install/hadoop/tmp</value>
<description>Parent directory for other temporary directories.</description>
</property>
<property>
<name>fs.defaultFS </name>
<value>hdfs://master:54310</value>
<description>The name of the default file system. </description>
</property>
```
![](/image/大数据06/大数据06_006.png)
* 3.移动到目录 **$HADOOP_HOME/etc/hadoop**

```bash
sudo mkdir -p <以上设置中使用的目录路径>
```

* 4.授权目录权限

```bash
sudo chown -R hadoop:hadoop <在上一步中创建的目录路径>
sudo chmod 750 <在上一步中创建的目录路径>
```

##### 配置文件系统

* 1.打开文件 $HADOOP_HOME/etc/hadoop/hdfs-site.xml 
```bash
sudo gedit $HADOOP_HOME/etc/hadoop/hdfs-site.xml
```
* 2.复制下面配置到 文件内容的 `<configuration>` 和 `</configuration>` 之间
```xml
<property>
<name>dfs.replication</name>
<value>1</value>
<description>Default block replication.</description>
</property>
<property>
<name>dfs.datanode.data.dir</name>
<value>/hadoop/install/hadoop/hdfs</value>
</property>
```
![](/image/大数据06/大数据06_008.png)
* 3.创建以上设置中指定的目录并授权
```bash
sudo mkdir -p /hadoop/install/hadoop/hdfs
sudo chown -R hadoop:hadoop /hadoop/install/hadoop/hdfs
sudo chmod 750 /hadoop/install/hadoop/hdfs
```

####  配置 **Map Reduce**

##### 配置环境变量

* 1.设置HADOOP_HOME路径
```bash
sudo gedit /etc/profile.d/hadoop.sh # 打开文件
export HADOOP_HOME=<Hadoop的安装路径> # 增加设置环境变量命令
sudo chmod +x /etc/profile.d/hadoop.sh # 脚本增加执行权限
```
* 2.增加脚本权限，并退出终端界面
```bash
sudo chmod +x /etc/profile.d/hadoop.sh # 脚本增加执行权限
# 重新登陆使用命令验证变量设置是否生效
echo $HADOOP_HOME
```

##### 配置MapReduce计算框架文件

* 1.复制文件 **mapred-site.xml** 并打开
```bash
sudo cp $HADOOP_HOME/etc/hadoop/mapred-site.xml.template $HADOOP_HOME/etc/hadoop/mapred-site.xml
sudo gedit $HADOOP_HOME/etc/hadoop/mapred-site.xml
```
* 2.复制下面配置到 文件内容的 `<configuration>` 和 `</configuration>` 之间
```xml
<property>
<name>mapreduce.jobtracker.address</name>
<value>master:54311</value>
<description>MapReduce job tracker runs at this host and port.
</description>
</property>
```
![](/image/大数据06/大数据06_007.png)

#### 配置 yarn-site.xml 文件

* 1.打开文件 $HADOOP_HOME/etc/hadoop/yarn-site.xml
```bash
sudo gedit $HADOOP_HOME/etc/hadoop/yarn-site.xml
```
* 2.复制下面配置到 文件内容的 `<configuration>` 和 `</configuration>` 之间
```xml
<property>
    <name>yarn.nodemanager.aux-services</name>
    <value>mapreduce_shuffle</value>
</property>
<property>
    <name>yarn.resourcemanager.address</name>
    <value>master:18040</value>
</property>
<property>
    <name>yarn.resourcemanager.scheduler.address</name>
    <value>master:18030</value>
</property>
<property>
    <name>yarn.resourcemanager.resource-tracker.address</name>
    <value>master:18025</value>
</property>
<property>
    <name>yarn.resourcemanager.admin.address</name>
    <value>master:18141</value>
</property>
<property>
    <name>yarn.resourcemanager.webapp.address</name>
    <value>master:18088</value>
</property>
```

### 格式化HDFS
```bash
$HADOOP_HOME/bin/hdfs namenode -format
```


### 启动Hadoop

* 1.使用以下命令启动hdfs
```bash
$HADOOP_HOME/sbin/start-dfs.sh
```
![](/image/大数据06/大数据06_009.png)

* 2.使用以下命令启动yarn
```bash
$HADOOP_HOME/sbin/start-yarn.sh
```
* 3.使用 **jps** 工具/命令，验证所有与Hadoop相关的进程是否正在运行。如果Hadoop已成功启动，则jps的输出应显示NameNode/NodeManager/ResourceManager/SecondaryNameNode/DataNode。
	![](/image/大数据06/大数据06_010.png)	

### 停止Hadoop

```bash
$HADOOP_HOME/sbin/stop-dfs.sh
$HADOOP_HOME/sbin/stop-yarn.sh
```