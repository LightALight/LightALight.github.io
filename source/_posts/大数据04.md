---
title: 大数据（四）大数据生态
date: 2019-07-15 19:23:32
tags: 大数据
copyright: true
password:
toc: true
---

海量数据就需要对应大数据技术去存储和处理它。

本文章主要介绍如何搭建大数据生态环境。

<!--more-->
## Quick Guide

现在搭建大数据环境有三种方式：

- 1.docker方式: 利用docker-compose一键编排部署
	- 优点：一键部署，快捷方便
	- 缺点：性能不高只适合测试环境或者学习

- 2.使用成熟的发行版本去部署：例如 CM(Cloudera Manager)+CDH（Cloudera’s Distribution Including Apache Hadoop）或者Ambari+HDP(Hortonworks Data Platform)
	- 优点：集群安装部署和运维方便
	- 缺点：屏蔽太多细节，妨碍对组件理解
	
- 3.使用开源版本：
  - 优点：  完全开源免费，社区活跃， 文档、资料详实 ，
  - 缺点： 集群安装部署复杂，需要编写大量配置文件，需要考虑组件之间的兼容性问题、版本匹配问题、冲突问题、编译问题等；  集群运维复杂，需要安装第三方软件辅助。  



### 机器准备

- 1.准备多台物理机或者使用VM安装多台虚机
- 2.从官网下载centos系统包并安装



### 机器配置

如果是docker方式部署，就不需要经历这个步骤

- 0.修改服务器的ip地址

```bash
vi /etc/sysconfig/network-scripts/ifcfg-eth0
BOOTPROTO="static"
ONBOOT=yes
IPADDR=192.168.52.100
NETMASK=255.255.255.0
GATEWAY=192.168.52.1
DNS1=8.8.8.8
```


例如：将准备好的三台服务器的IP地址分别设置成为如下：
- 第一台机器IP地址：192.168.52.100
- 第二台机器IP地址：192.168.52.110
- 第三台机器IP地址：192.168.52.120
- 第四台机器IP地址：192.168.52.130

- 1.关闭防火墙

```bash
# centos 7 默认使用的是firewall，也可以使用iptables配置规则
systemctl stop firewalld.service
systemctl mask firewalld.service

service iptables status # 查看状态
service iptables stop # 临时关闭
chkconfig iptables --list # 查看防火墙启动级别
chkconfig iptables off # 永久关闭
```

- 2.关闭SELinux（所有节点）

```bash
# 使用root用户登录四台服务器，执行以下命令关闭selinux
vim /etc/selinux/config
SELINUX=enforcing # 注释掉
SELINUX=disabled # 添加
/usr/sbin/sestatus -v # 查看状态
```

- 3.修改主机名

```bash
# 在不同机器上执行
hostnamectl set-hostname master
hostnamectl set-hostname node01
hostnamectl set-hostname node02
hostnamectl set-hostname node03
```


- 4.更改主机名与IP地址映射

```
vim /etc/hosts
192.168.52.100 master.kaikeba.com master
192.168.52.110 node01.kaikeba.com node01
192.168.52.120 node02.kaikeba.com node02
192.168.52.130 node03.kaikeba.com node03
```

- 5.主机间ntp同步时间

```bash
yum -y install ntpdate
crontab -e
*/1 * * * * /usr/sbin/ntpdate time1.aliyun.com # 这边使用的阿里云的ntp服务器，如果不能访问外网，就应该配置内网的ntp服务器
```

- 6.添加普通用户

```bash
# 创建hadoop，并设置密码为 hadoop 
sudo addgroup hadoop # 新建用户组   
sudo adduser --ingroup hadoop hadoop # 新建用户
passwd hadoop
# 给用户增加roo权限：在（root ALL=(ALL)ALL）在下面添加一行
sudo vim /etc/sudoers
hadoop ALL=(ALL) ALL
```

- 7.配置免密登录

```bash
# 生成私钥和公钥,在/home/当前用户/.ssh目录下找到id_rsa(私钥)和id_rsa.pub(公钥)
ssh-keygen -t rsa
 
#三台机器在hadoop用户下，执行以下命令将公钥拷贝到master服务器上面去
ssh-copy-id master
 
# master在hadoop用户下，执行以下命令，将authorized_keys拷贝到 node01、node02与node03服务器
cd /home/hadoop/.ssh/
scp authorized_keys node01:$PWD
scp authorized_keys node02:$PWD
scp authorized_keys node03:$PWD
```

- 8.定义统一目录

```bash
mkdir -p /hadoop/soft # 软件压缩包存放目录
mkdir -p /hadoop/install # 软件解压后存放目录
chown -R hadoop:hadoop /hadoop # 将文件夹权限更改为hadoop用户
```

- 9.安装java

```bash
# 从官网下载jdk包，解压到目录
tar -zxf jdk-8u141-linux-x64.tar.gz -C /hadoop/install
 
sudo vim /etc/profile

#添加以下配置内容，配置jdk环境变量
export JAVA_HOME=/hadoop/install/jdk1.8.0_141
export PATH=:$JAVA_HOME/bin:$PATH
```

- 10.在root用户下重启

```bash
reoot -h now
```



###  Docker 部署

不少公司把所有的 大数据组件都做成了 docker image ，可以直接通过 docker-compose 一键按照，具体看一下参考下面的教程：
- [安装教程1](https://clubhouse.io/developer-how-to/how-to-set-up-a-hadoop-cluster-in-docker/)
- [安装教程2](https://hub.docker.com/r/bde2020/hadoop-namenode)





### CM + CDH 部署

- CM：Cloudera Manager，Cloudera公司编写的一个CDH的管理后台，类似各CMS的管理后台。
- CDH：Cloudera’s distribution,including Apache Hadoop，Cloudera公司制作的一个Hadoop发行版，集成了Hadoop及Hive等与Hadoop关系紧密的工具。

- 1.下载

	- 根据操作系统从[CM bin文件](http://archive.cloudera.com/cm5/redhat/6/x86_64/cm/)下载对应版本
	- 根据操作系统从[CM rpm包]http://archive.cloudera.com/cm5/redhat/6/x86_64/cm/)下载对应版本
	- 根据操作系统从[CDH](http://archive.cloudera.com/cdh5/parcels/)下载对应版本的manifest.json、.parcel和.sha1文件

- 2.上传介质到master，上传目录为/hadoop/soft，并解压


```bash
tar -zxvf cm5.5.1.tar.gz 
tar -zxvf cdh5.5.1.tar.gz
```

- 3.各个节点配置本地yum源（master）

```bash
cd /etc/yum.repos.d
vi cloudera-manager.repo
```
添加下面内容

```
[cloudera-manager]
name=Cloudera Manager, Version 5.5.1
baseurl=http://192.168.52.100/cm5.5.1
gpgcheck=0
```

- 4.启动http服务

```bash
service httpd status # 查看服务状态
service httpd start # 打开服务
```


- 5.验证本地yum源

	- 将上一步baseurl地址粘贴到浏览器
	- 确认是否能正常访问到已经上传安装文件的机器的安装文件目录。

- 6.运行CM安装

```bash
# 赋予bin文件执行权限
chmod u+x cloudera-manager-installer5.5.1.bin
cd /hadoop/soft
# 运行bin文件
./cloudera-manager-installer5.5.1.bin
```

- 7.验证CM安装是否完成
	- 使用命令查看服务状态：service cloudera-scm-server status
	- 点击 管理界面(http://192.168.52.100:7180/cmf) 登陆，用户名和密码都为admin

- 8.修正参数

```bash
echo 0 > /proc/sys/vm/swappiness
echo never > /sys/kernel/mm/transparent_hugepage/defrag
echo never > /sys/kernel/mm/transparent_hugepage/enabled
```

- 9.开始安装
    - 1.接受许可
    - 2.选择相应的版本
    - 3.选择主机：搜索主机，也可以自己输ip
    - 4.选择存储库：使用Parcel，远程Parcel 存储库URL指定安装源(本地源)
    - 5.勾选JDK
    - 6.填写用户（hadoop）密码
    - 7.开始安装
    - 8.自定义添加服务
    - 9.安装角色
    - 10.数据库选择：建议使用默认数据库。以后可以进行修改。
    - 11.指定数据目录

- 10.排错
    - 1.完成以上，说明集群已经安装成功，其他问题需要在后续过程调试。页面显示红色不等于服务没有安装成功，验证参数没有满足默认而已。
    - 2.关闭时钟同步
    - 3.验证安装：例如 到安装HDFS角色的服务器上任意目录执行如下命令（hadoop fs -ls /），能正常执行即代表功能可用




###  开源版本部署

从下图可以知道，使用开源版本部署比较麻烦，组件比较多，后面就一章一章慢慢说。

![](/image/大数据04/大数据04_001.jpg)



